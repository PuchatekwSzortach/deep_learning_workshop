{% import "math_macros.html" as math_macros %}


{% macro card_header_style() %}
"h3 card-header text-center bg-success text-white"
{% endmacro %}


{% macro kuba_profile() %}
<div class="shadow-lg">

    <div class={{ card_header_style() }}>Kuba Kolodziejczyk</div>

    <div class="row">
        <div class="col-md-8">
            <div class="m-4 h4">
                <strong>出身:</strong> ポーランド<br>
                <strong>大学:</strong> ロンドン大学, 大阪大学<br><br>

                <strong>過去</strong><br>
                Nanyang Technological University<br>
                OIST<br>
                レキサス<br><br>

                <strong>現在</strong><br>
                AI Okinawa - 代表<br>
                LiLz株式会社 - CTO<br>
                琉球大学 - 非常勤講師
            </div>
        </div>

        <div class="col-md-4">
          <img src="/static/images/profile_image.jpg" class="mx-auto d-block" width="100%">
        </div>

    </div>
</div>
{% endmacro %}


{% macro what_this_course_is_about() %}
<div class="shadow-lg">
    <div class={{ card_header_style() }}>What this course is about</div>
    <div class="m-4">
        <img src="/static/images/neural_network_example.png" width="80%"><br>
        <div class="h5 text-center text-secondary small">neuralnetworksanddeeplearning.com</div>
        <hr>
    </div>
</div>
{% endmacro %}


{% macro deep_learning_overview() %}
<div class="shadow-lg">
    <div class={{ card_header_style() }}>Deep learning - short overview</div>
    <div class="m-4">
        <img src="/static/images/ai_ml_dl.jpg" width="80%"><br>
        <div class="h5 text-center text-secondary small">rapidminer.com</div>
        <hr>
        <br>
        <img src="/static/images/sample_function.jpg" width="80%">
        <div class="h2">$$ y = ax^3 + bx^2 + cx + d$$</div>
        <hr>
        <img src="/static/images/various_deep_learning_examples.jpg" width="100%"><br>

    </div>
</div>
{% endmacro %}


{% macro ask_questions_take_notes() %}
<div class="jumbotron text-center card mt-4 p-4 shadow-lg">
    <h1>Ask questions</h1>
    <h1>Take notes</h1>
    <h1>Create a cheat-sheet</h1>
</div>
{% endmacro %}


{% macro sample_forward_propagation_computations() %}
    <div class="shadow-lg">
        <div class={{ card_header_style() }}>Sample forward propagation computations</div>

        <div class="m-4">

            <div class="row">

                <div class="col"></div>
                <div class="col">
                    <table class="table table-bordered text-center">
                        <div class="caption text-center h6">Inputs</div>
                        <tbody>
                            <tr>
                                <td>\( x_1 \)</td>
                                <td>\( 4 \)</td>
                            </tr>
                            <tr>
                                <td>\( x_2 \)</td>
                                <td>\( 0.5 \)</td>
                            </tr>
                        </tbody>
                    </table>
                </div>
                <div class="col"></div>

            </div>
            <hr>
            <div class="row">

                <div class="col"></div>
                <div class="col">
                    <table class="table table-bordered text-center">
                        <div class="caption text-center h6">Parameters</div>
                        <tbody>
                            <tr>
                                <td>\( w_1 \)</td>
                                <td>\( 1 \)</td>
                            </tr>
                            <tr>
                                <td>\( w_2 \)</td>
                                <td>\( -1 \)</td>
                            </tr>
                            <tr>
                                <td>\( b \)</td>
                                <td>\( -2 \)</td>
                            </tr>
                        </tbody>
                    </table>
                </div>
                <div class="col"></div>

            </div>
            <hr>

            <div class="text-center h6">Preactivation</div>
            $$ z = (w_1 * x_1) + (w_2 * x_2) + b $$
            $$ z = (1 * 4) + (-1 * 0.5) - 2 $$
            $$ z = 4 - 0.5 - 2 = 1.5 $$
            <hr>
            <div class="text-center h6">Activation</div>
            $$ a = \sigma(z) = \frac{1}{1 + e^{-z}} $$
            $$ a = \sigma(1.5) = \frac{1}{1 + e^{-1.5}} $$
            $$ a = 0.82 $$

        </div>
        <br>
    </div>
{% endmacro %}


{% macro cost_function() %}
<div class="shadow-lg">
    <div class={{ card_header_style() }}>Cost function</div>
    <div class="m-4">

        <ul class="list-group">
            <li class="list-group-item">Why use cost function?</li>
            <li class="list-group-item">Gradient descent</li>
            <li class="list-group-item">Why not just use accuracy?</li>
        </ul>
    </div>
    <br>
</div>
{% endmacro %}


{% macro cost_derivative_with_respect_to_activation() %}
<div class="shadow-lg">
    <div class={{ card_header_style() }}>Cost derivative with respect to activation</div>
    {{ math_macros.cost_derivative_with_respect_to_activation() }}
    <br>
</div>
{% endmacro %}


{% macro cost_derivative_with_respect_to_preactivation() %}
<div class="shadow-lg">
    <div class={{ card_header_style() }}>Cost derivative with respect to preactivation</div>
    $$ \frac { \partial{C} }{ \partial{z} } = \frac { \partial{C} }{ \partial{a} } * \frac { \partial{a} }{ \partial{z} }$$
    <hr>
    {{ math_macros.sigmoid_derivative_computations() }}
    <hr>
    $$ \frac { \partial{C} }{ \partial{z} } = \frac { \partial{C} }{ \partial{a} } * a * (1 - a) $$
    <br>
</div>
{% endmacro %}


{% macro cost_derivative_with_respect_to_parameters() %}
<div class="shadow-lg">
    <div class={{ card_header_style() }}>Cost derivative with respect to parameters</div>

    <div class="m-4">

        <ul class="list-group">
            <li class="list-group-item">Cost derivative with respect to weights</li>
            <li class="list-group-item">Cost derivative with respect to bias</li>
        </ul>
    </div>
    <br>

</div>
{% endmacro %}


{% macro parameters_update() %}
<div class="shadow-lg">
    <div class={{ card_header_style() }}>Parameters update</div>

    <div class="m-4">

        <ul class="list-group">
            <li class="list-group-item">Learning rate</li>
            <li class="list-group-item">Weights update</li>
            <li class="list-group-item">Bias update</li>
        </ul>
    </div>
    <br>

</div>
{% endmacro %}


{% macro networks_with_multiple_outputs() %}
<div class="shadow-lg">
    <div class={{ card_header_style() }}>Networks with multiple outputs</div>
    <div class="m-4">

        <ul class="list-group">
            <li class="list-group-item">One-hot encoding</li>
            <li class="list-group-item">Computing cost over multiple outputs</li>
        </ul>
    </div>
    <br>
</div>
{% endmacro %}


{% macro backpropagation_in_complex_networks() %}
<div class="shadow-lg">
    <div class={{ card_header_style() }}>Backpropagation - complex networks</div>
    <div class="m-4">

        <ul class="list-group">
            <li class="list-group-item">Cost derivative w.r.t. hidden node activation</li>
            <li class="list-group-item">Parameters notation for complex networks</li>
            <li class="list-group-item">Compute layer error on node with multiple children</li>
        </ul>
    </div>
    <br>
</div>
{% endmacro %}


{% macro matrix_review() %}
<div class="shadow-lg">
    <div class={{ card_header_style() }}>Matrix review</div><br>

    {{ math_macros.matrix_multiplication() }}
    <hr>
    {{ math_macros.derivative_of_vector_with_respect_to_scalar() }}
    <hr>
    {{ math_macros.derivative_of_scalar_with_respect_to_vector() }}

</div>
{% endmacro %}


{% macro matrix_notation_forward_pass() %}
<div class="shadow-lg">
    <div class={{ card_header_style() }}>Matrix notation - forward pass</div><br>

    {{ math_macros.matrix_notation_preactivation() }}
    <hr>
    {{ math_macros.matrix_notation_activation() }}

</div>
{% endmacro %}


{% macro matrix_notation_backpropagation_error_with_respect_to_output_activation_vector() %}
<div class="shadow-lg">
    <div class={{ card_header_style() }}>
        Matrix notation backpropagation<br>
        Derivative of cost w.r.t. last activation vector</div><br>

    {{ math_macros.derivative_of_cost_with_respect_to_last_activation_vector() }}
</div>
{% endmacro %}


{% macro matrix_notation_backpropagation_error_with_respect_to_preactivation_vector() %}
<div class="shadow-lg">
    <div class={{ card_header_style() }}>
        Matrix notation backpropagation<br>
        Derivative of cost w.r.t. preactivation vector</div><br>

    {{ math_macros.derivative_of_cost_with_respect_to_preactivation_vector() }}
</div>
{% endmacro %}


{% macro matrix_notation_backpropagation_error_with_respect_to_hidden_layer_activation_vector() %}
<div class="shadow-lg">
    <div class={{ card_header_style() }}>
        Matrix notation backpropagation<br>
        Derivative of cost w.r.t. hidden layer's activation vector</div><br>

    {{ math_macros.derivative_of_cost_with_respect_to_hidden_layer_activation_vector() }}
</div>
{% endmacro %}


{% macro matrix_notation_backpropagation_error_with_respect_to_weights_matrix() %}
<div class="shadow-lg">
    <div class={{ card_header_style() }}>
        Matrix notation backpropagation<br>
        Derivative of cost w.r.t. weights matrix</div><br>

    {{ math_macros.derivative_of_cost_with_respect_to_weights_matrix() }}
</div>
{% endmacro %}


{% macro matrix_notation_backpropagation_error_with_respect_to_biases_vector() %}
<div class="shadow-lg">
    <div class={{ card_header_style() }}>
        Matrix notation backpropagation<br>
        Derivative of cost w.r.t. biases vector</div><br>

    {{ math_macros.derivative_of_cost_with_respect_to_biases_vector() }}
</div>
{% endmacro %}


{% macro batching() %}
<div class="shadow-lg">
    <div class={{ card_header_style() }}>Batching</div>
    <div class="m-4">
        <ul class="list-group">
            <li class="list-group-item">Problem with optimizing for a single sample</li>
            <li class="list-group-item">Optimizing for a batch of samples</li>
            <li class="list-group-item">Matrix notation for training a batch of samples</li>
            <li class="list-group-item">Computational complexity</li>
            <li class="list-group-item">Updates count</li>
        </ul>
    </div>
    <br>
</div>
{% endmacro %}


{% macro optimizing_cost_function() %}
<div class="shadow-lg">
    <div class={{ card_header_style() }}>Optimizing cost function</div>
    <div class="m-4">
        <ul class="list-group">
            <li class="list-group-item">Sigmoid derivative and slow learning with mean square error function</li>
            <li class="list-group-item">Binary cross entropy</li>
            <li class="list-group-item">Preactivation error with binary cross entropy cost function</li>
        </ul>
    </div>
    <br>
</div>
{% endmacro %}


{% macro softmax() %}
<div class="shadow-lg">
    <div class={{ card_header_style() }}>Softmax</div>
    <div class="m-4">
        <ul class="list-group">
            <li class="list-group-item">Interpreting result of neural network with multiple output nodes</li>
            <li class="list-group-item">Softmax function</li>
            <li class="list-group-item">Cross entropy cost</li>
            <li class="list-group-item">Cost derivative w.r.t. active node</li>
            <li class="list-group-item">Cost derivative w.r.t. inactive node</li>
        </ul>
    </div>
    <br>
</div>
{% endmacro %}


{% macro optimizing_hidden_layer_activation_function() %}
<div class="shadow-lg">
    <div class={{ card_header_style() }}>Optimizing hidden layer activation function</div>
    <div class="m-4">
        <ul class="list-group">
            <li class="list-group-item">Sigmoid derivative and its effect on gradients across layers</li>
            <li class="list-group-item">ReLU - rectified linear unit</li>
            <li class="list-group-item">Derivative of ReLU</li>
            <li class="list-group-item">Why not use a linear hidden activation?</li>
        </ul>
    </div>
    <br>
</div>
{% endmacro %}


{% macro importance_of_weights_initialization_scheme() %}
<div class="shadow-lg">
    <div class={{ card_header_style() }}>Importance of weights initialization scheme</div>
    <div class="m-4">
        <ul class="list-group">
            <li class="list-group-item">Problem with naive weights initialization</li>
            <li class="list-group-item">Scaling weights initialization w.r.t. input size</li>
        </ul>
    </div>
    <br>
</div>
{% endmacro %}